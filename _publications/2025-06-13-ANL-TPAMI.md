---
title: "Active Negative Loss: A Robust Framework for Learning with Noisy Labels"
collection: publications
category: preprint
permalink: /publication/2025-ANL-plus
date: 2025-06-13
venue: 'IEEE Transactions on Pattern Analysis and Machine Intelligence'
authors: "Xichen Ye*, <strong>Yifan Wu*</strong>, Yiqi Wang, Xiaoqiang Li<sup>#</sup>, Weizhong Zhang, Yifan Chen<sup>#</sup>"
paperurl: 'https://arxiv.org/abs/2412.02373'
---
Deep supervised learning has achieved remarkable success across a wide range of tasks, yet it remains susceptible to overfitting when confronted with noisy labels. To address this issue, noise-robust loss functions offer an effective solution for enhancing learning in the presence of label noise. In this work, we systematically investigate the limitation of the recently proposed Active Passive Loss (APL), which employs Mean Absolute Error (MAE) as its passive loss function. Despite the robustness brought by MAE, one of its key drawbacks is that it pays equal attention to clean and noisy samples; this feature slows down convergence and potentially makes training difficult, particularly in large-scale datasets. To overcome these challenges, we introduce a novel loss function class, termed Normalized Negative Loss Functions (NNLFs), which serve as passive loss functions within the APL framework. NNLFs effectively address the limitations of MAE by concentrating more on memorized clean samples. By replacing MAE in APL with our proposed NNLFs, we enhance APL and present a new framework called Active Negative Loss (ANL). Moreover, in non-symmetric noise scenarios, we propose an entropy-based regularization technique to mitigate the vulnerability to the label imbalance. Extensive experiments demonstrate that the new loss functions adopted by our ANL framework can achieve better or comparable performance to state-of-the-art methods across various label noise types and in image segmentation tasks. The source code is available at: https://github.com/Virusdoll/Active-Negative-Loss.
